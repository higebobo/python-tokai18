.. -*- mode: rst -*- coding: utf-8 -*-

===================================
Pythonでビジネスインテリジェンス(1)
===================================

by higebobo at Python東海第18回勉強会


おことわり
==========

* どちらかというと自分の備忘録代わりに作っている資料

* なので極端に簡単すぎることも説明してあるかも


Pythonで統計処理する場合
========================

* 自前で実装するかライブラリの利用

* 複雑な処理をする場合は事実上2パターンになる

  - rpy2(Rのインターフェース)

    + rpyの後継。rpyは事実上開発停止
    
  - Numpy/Scipy(以下Scipyと省略)

    + 数値計算・科学計算モジュール


でどちらがいいの
================

* PythonistaならScipy+Matplotlibで史上最強統計ソフトといいたい所だが

* 結局のところ一長一短があるので使い分けするのがベター

* Scipyの場合

  - データの取り扱い・名前空間などよりPythonicな利用ができる
  - より基礎的な計算ライブラリのため利用者にある程度専門知識が求められる

* Rの場合

  - 統計処理に特化しているので豊富な一発コマンドが準備されていて便利
  - ウェブでの情報も多い
  - ただしPythonから外部コマンドで呼び出している感は否めない


統計ソフトRのインストールについて
=================================

* 各種プラットフォーム向けにインストールパッケージがある
* ただしWindowsでrpy2を使う場合は以下の組み合わせになる

  - R: 2.1.1 (R-2.11.1-win32.exe)
  
  - rpy2: 2.0.8 (rpy2-2.0.8.win32-py2.6.msi)
  
    - 上記組み合わせでないと正常に動作しない
    - rpy2を野良ビルドする場合はこの限りではないと思う
    - rpy2-2.0と最新版rpy2-2.1で大幅な仕様変更があるため注意


超速習rpy2
==========

* Rの知識は不可欠
* rpy2を使うために最低限知っておくメソッド

  - 外部ファイルからのデータ読み込み

    + read.table, read.csv他

  - r_repr
  
* ついでに覚えておくとよいメソッド

  - globalenv (or globalEnv)

    + RとPythonの名前空間の行き来(r_reprの冗長的な記述回避)
  
  - ベクトルの扱い

    + IntVector, FloatVector, StrVector

* スライス


超速習Scipy
===========

* 外部ファイル読み込み

  - 型の混在するarrayは作成できないので注意
  
* スライス


基本統計量の算出
================

* ベクトル(一元配列)で以下を算出する

  - データ個数
  - 平均値
  - 合計値
  - 分散
  - 標準偏差
  - 標本標準誤差

* 後はその組み合わせとなる


実際に計算してみる(前置き)
==========================

* Pure Python / R / Scipyを使って実際に計算してみる

* 使用データは以下とする

  - Python ::

      data = [1, 3, 10, 5, 100]

  - R ::

      data = robjects.IntVector([1, 3, 10, 5, 100])

  - Scipy ::

      data = numpy.array([1, 3, 10, 5, 100])

* 計算式において一度定義した変数は使いまわす


データ個数
==========

* 要素数

  - Python ::

      size = len(data)

  - R ::

      size = r.length(data)[0]

  - Scipy ::

      size = data.size #or data.shape[0]


合計値
======

* 要素の総和

  - Python ::

      total = sum(data)

  - R ::

      total = r.sum(data)[0]

  - Scipy ::

      total = data.sum()


平均値
======

* 要素の平均

  - Python ::

      mean = total / size

  - R ::

      mean = r.mean(data)[0]

  - Scipy ::

      mean = data.mean()

分散
====

* 平方和(各要素と平均値との差を2乗したものの総和)をデータ個数で除する

  - Python ::

      variance = sum(((x-mean)**2 for x in data)) / size

  - R ::

      variance = r.var(data)[0]*(size-1)/size

  - Scipy ::

      variance = data.var()

標準偏差
========

* 標準偏差

  - Python ::

      std = math.sqrt(variance)

  - R ::

      std = r.sqrt(variance)[0]

  - Scipy ::

      std = data.std()

標準誤差
========

* 標準誤差

  - Python ::

      unbiased_variance = sum(((x-mean)**2 for x in data))/(size-1)
      stderr = math.sqrt(unbiased_variance/size)

  - R ::

      stderr = r('sqrt(var(%s)/length(%s))'%(data.r_repr(), data.r_repr()))

  - Scipy ::

      from scipy.stats import sem
      stderr = sem(data)


ここだけ見ると
==============

* Scipyに軍配があがる

  - たぶん早い
  - だいたい1行でかける
  - Scipyメソッドあるいはarrayオブジェクトのメソッドとして記述できる ::

      mean = data.mean()
      mean = scipy.mean(data)

  - 当たり前だけどPython風にもかける ::

      mean = sum(data) / len(data)

* しかしRにはRのメリットが。。。


どうでもいいけど
================

* ちなみに統計用語は英語でなんと表現するか知っておくことはとても重要
* RでもScipyでも関数の使い方を調べたりするのに英語表現がわかってないとつらい


ではウェブ教材を元に統計のお勉強
================================
  
* ハンバーガーショップで学ぶ楽しい統計学

  http://dl.dropbox.com/u/2982832/elearn/hamburger/index.html

* アイスクリーム屋さんで学ぶ楽しい統計学

  http://dl.dropbox.com/u/2982832/elearn/icecream/index.html


2つのデータの有意差を調べる
===========================

* t検定

  - 独立した2標本の平均値の差に関する検定

* 2つのバーガーショップで任意の女子高生8人に100点満点で味を評価してもらう

  - 女子高生である必要があるかは疑問
  
* その結果に統計的な有意差があるか(つまり店の味に優劣があるか)を判断する


アンケート集計結果
==================

ワクワクバーガーとモグモグバーガーを対象に任意の10名に味を評価

====== ========== ==========
 番号   ワクワク   モグモグ
------ ---------- ----------
 1      70         85
 2      75         80
 ...   ...         ...
 7      80         80
 8      75         90
------ ---------- ----------
 平均   76.88      81.88
------ ---------- ----------
 分散   49.61      55.86
====== ========== ==========


仮説検定
========

* 帰無仮説(Null hypothesis)「2つの標本の平均値に差はない」を立てる
* 対立仮説(Alternative hypothesis)は「2つの標本の平均値に有意差がある」となる
* 検定を行い帰無仮説か対立仮説の採択を決める(一方は棄却)


いざt検定
=========

* 2つのハンバーガーショップの味の評価平均値に関する帰無仮説

  「ワクワクバーガー(76.88)とモグモグバーガー(81.88)の間に有意差はない」


t検定の方法
===========

* その1

  - t値を算出しt分布表の値と比較

    + t分布表の値は自由度と有意水準から求められる

  - t値がt分布値よりも大きければ帰無仮説は棄却→有意差がある

* その2

  - p値を算出し、有意水準(0.05, 0.01)と比較

  - p値が有意水準より小さければ帰無仮説は棄却→有意差がある

    + p値が1の場合2標本のデータは同一


検証結果1
=========

* Pure Pythonによる計算結果

  - t値 -> -1.29 (絶対値1.29)
  
  - t分布(有意水準0.05) -> 2.145
  
    + t値の1.29は2.145よりも小さいので有意水準は5%で帰無仮説は棄却できない
  
  - t分布(有意水準0.01) -> 2.977

    - t値の1.29は2.977よりも小さいので有意水準は1%で帰無仮説は棄却できない


検証結果2
=========

* R、Scipyによる計算結果

  - t値 -> -1.29
  
  - p値 -> 0.22

    + p値0.22は0.05よりも大きいので有意水準は5%で帰無仮説は棄却できない
      
    + p値0.22は0.01よりも大きいので有意水準は1%で帰無仮説は棄却できない


で結局結論はどうよ
==================

* 仮説とかが否定から始まってそれをさらに否定することはできないとか二重
  否定、三重否定になって頭こんがら

* ようするに「差がない」 帰無仮説を採択したってこと


そもそも独立した2標本ってなによ
===============================

* つまり2つのバーガーショップで任意に調査したということ(independent t-test)

* 一方同じ人にそれぞれ2つのショップで評価してもらう場合はペア検定
  (paired t-test)となる


ペア検定のサンプル
==================

* ペア検定は店の平均は関係なく女子高生の評価点の差異を解析する

========== ========== ==========
 女子高生   ワクワク   モグモグ
---------- ---------- ----------
 1          90         95
 2          75         80
 ...        ...         ...
 7          75         80
 8          80         85
---------- ---------- ----------
 平均       76.88      81.25
========== ========== ==========


検証結果
========

* p値 -> 0.0209375702069

  - 有意水準0.05で帰無仮説棄却 -> 味の差がないとはいえない
  - 有意水準0.01で帰無仮説採択 -> 味の差がない

* t値 -> -2.96561491008

  - t分布(有意水準0.05) -> 2.36462425159

    + 帰無仮説棄却
    
  - t分布(有意水準0.01) -> 3.49948329735

    + 帰無仮説採択


独立検定とペア検定
==================

* ペア検定は2標本のデータ数は等しくなければならないが独立検定はその限りで無い

* 計算ロジックはペア検定のほうがよりシンプルになる

* またペア検定は同一対象での調査になるので標準誤差が小さくなる

* つまりより確実なデータの検出ができるといえる


3つ以上のデータの有意差を調べる場合
===================================

* t検定は2つの標本でしかできない

* 3つ以上ある場合は分散分析(ANOVA: analysis of variance)を行う

* 要因数に応じて解析が異なる

  - 1要因(One-Way Analysis of Variance)
  
  - 2要因(Two-Way Analysis of Variance)


1要因分散分析
=============

* 前回同様にバーガーショップの味を評価
* 今回は3店舗
* 評価する人は任意(独立)


3店舗のポテトの味の評価結果
============================

========== ========== ==========
 ワクワク   モグモグ   パクパク
---------- ---------- ----------
 80           75         80
 75           70         80
 ...         ...        ...                        
 85           90         85
 80           80         85
========== ========== ==========


検証結果
========

* p値 -> 3.82482645839e-05

  - 有意水準0.001で帰無仮説棄却 -> 平均に差はないとはいえない

* F値 -> 12.2231101945

  - F分布(有意水準0.05) -> 3.15884271926

    + 帰無仮説棄却
    
  - F分布(有意水準0.01) -> 4.99810955622

    + 帰無仮説棄却


t分布とF分布について
====================

* Pure Pythonモデルでは分布表をリストとして定義した
* 実際は数式から算出するもの
* t分布はgamma関数, F分布はB関数により算出される
* gamma関数はPython 3.2のmathモジュールで標準組み込みになっている


予測モデル
==========

* データに規則性が見出せれば予測モデルを作成することができる
* ここでは単回帰分析を用いる


単回帰分析とは
==============

* 一つの従属変数から一つの独立変数を予測する
* 線形回帰ではY = a + bX という回帰直線を当てはめる
* この傾きbと切片aを最小二乗法で求める


駅からの距離と来客数の関係
==========================

アイスクリーム店の最寄の駅からの距離と来客数にどのような関係があるかを調べる

====== ====== ========
 店舗   距離   客平均
------ ------ --------
   1      10   795
   2    1200   213
 ...     ...   ...
  11     620   385
  12      65   723
====== ====== ========


手順
====

* 最初に散布図を書いて傾向を見る

* 次に相関係数を算出

* モデル式を算出

* プロット


結果
====

* 相関係数が-0.98と非常に高い結果となった

  - ±0.7以上で強い相関。±1で完全一致

* 予測モデルとしても精度の高いものになろう


おしまい
========

* ご静聴ありがとうございました。

* 次回は実際に仕事で分析した内容について紹介する予定です。

.. raw:: html

   <script type="text/javascript">
   var head = document.getElementsByTagName('head')[0];
   var configuration = {tranSitions:true,
                        fadeDuration:500,
                        incrDuration:250,
                        autoMatic:false,
                        playLoop:true,
                        playDelay:10,
                        audioSupport:true,
                        audioVolume:100,
                        audioError:true,
                        audioDebug:false};
   for (var name in configuration) {
       var meta = document.createElement('meta');
       meta.setAttribute('name', name);
       meta.setAttribute('content', configuration[name]);
       head.appendChild(meta);
   }

   var e=document.getElementsByTagName('ul');
   for (var i = 0; i < e.length; ++i) {
      e[i].className += ' incremental';
      // e[i].className += ' scale fs90';
   }

   try {
       var style = document.createElement('style');
       style.innerHTML = ['* {font-family: "MS PGothic",sans-serif}'
                         ,'pre,tt {font-family: "MS Gothic",monospace}'
                         ,'.slide pre {color:black}'
                         ,'.slide tt {color:black}'
                         ,'.slide .incremental, .slide .incremental *, .slide .incremental *:after {visibility: hidden;}'
                         ].join('\n');
       head.appendChild(style);
   } catch(e) {}
   </script>